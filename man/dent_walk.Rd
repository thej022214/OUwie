% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dentist.R
\name{dent_walk}
\alias{dent_walk}
\title{Sample points from along a ridge}
\description{
This "dents" the likelihood surface by reflecting points better than a threshold back across the threshold (think of taking a hollow plastic model of a mountain and punching the top so it's a volcano). It then uses essentially a Metropolis-Hastings walk to wander around the new rim. It adjusts the proposal width so that it samples points around the desired likelihood.
This is better than using the curvature at the maximum likelihood estimate since it can actually sample points in case the assumptions of the curvature method do not hold. It is better than varying one parameter at a time while holding others constant because that could miss ridges: if I am fitting 5=x+y, and get a point estimate of (3,2), the reality is that there are an infinite range of values of x and y that will sum to 5, but if I hold x constant it looks like y is estimated very precisely. Of course, one could just fully embrace the Metropolis-Hastings lifestyle and use a full Bayesian approach.

While running, it will display the current range of likelihoods in the desired range (by default, the best negative log likelihood + 2 negative log likelihood units) and the parameter values falling in that range. If things are working well, the range of values will stabilize during a search.}
\usage{
dent_walk(
  par,
  fn,
  best_neglnL,
  delta = 2,
  nsteps = 1000,
  print_freq = 50,
  lower_bound = 0,
  upper_bound = Inf,
  adjust_width_interval = 100,
  badval = 1e+09,
  sd_vector = NULL,
  debug = FALSE,
  restart_after = 50,
  ...
)
}
\arguments{
\item{par}{Starting parameter vector, generally at the optimum. If named, the vector names are used to label output parameters.}

\item{fn}{The likelihood function, assumed to return negative log likelihoods}

\item{best_neglnL}{The negative log likelihood at the optimum; other values will be greater than this.}

\item{delta}{How far from the optimal negative log likelihood to focus samples}

\item{nsteps}{How many steps to take in the analysis}

\item{print_freq}{Output progress every print_freq steps.}

\item{lower_bound}{Minimum parameter values to try. One for all or a vector of the length of par.}

\item{upper_bound}{Maximum parameter values to try. One for all or a vector of the length of par.}

\item{adjust_width_interval}{When to try automatically adjusting proposal widths}

\item{badval}{Bad negative log likelihood to return if a non-finite likelihood is returned}

\item{sd_vector}{Vector of the standard deviations to use for proposals. Generated automatically if NULL}

\item{debug}{If TRUE, prints out much more information during a run}

\item{restart_after}{Sometimes the search can get stuck outside the good region but still accept moves. After this many steps without being inside the good region, restart from one of the past good points}

\item{...}{Other arguments to fn.}
}
\value{
A dentist object containing results, the data.frame of negative log likelihoods and the parameters associated with them; acceptances, the vector of whether a proposed move was accepted each step; best_neglnL, the best value passed into the analysis; delta, the desired offset; all_ranges, a summary of the results.
}
\details{
The algorithm tunes: if it is moving too far away from the desired likelihoods, it will decrease the proposal width; if it staying in areas better than the desired likelihood, it will increase the proposal width. It will also expand the proposal width for parameters where the extreme values still appear good enough to try to find out the full range for these values.

In general, the idea of this is not to give you a pleasingly narrow range of possible values -- it is to try to find the actual uncertainty, including finding any ridges that would not be seen in univariate space.
}
